{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a467425a",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üé≠ Face Landmarks Detection using MediaPipe</h2>\n",
    "\n",
    "This notebook demonstrates **real-time Face Mesh detection** using **MediaPipe** and **OpenCV**.  \n",
    "It detects **468 facial landmarks** per face and can track multiple faces simultaneously.  \n",
    "This module is fully compatible with **VSCode** and **Google Colab**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd9d98",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üß† Theory Overview</h2>\n",
    "\n",
    "**MediaPipe Face Mesh** uses a lightweight, real-time 3D face landmark model.  \n",
    "It combines two models:\n",
    "1. **Face Detection Model** ‚Äî identifies the location of the face.  \n",
    "2. **Face Landmark Model** ‚Äî predicts 468 3D landmarks on each detected face.\n",
    "\n",
    "**Applications:**\n",
    "- AR Filters (Instagram, Snapchat)\n",
    "- Virtual Makeup / Face Retouching\n",
    "- Facial Expression Tracking\n",
    "- Head Pose Estimation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ace9ea",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">‚öôÔ∏è Setup and Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "823358e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f9698",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üíª Initialize Face Mesh Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50bb51ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaPipe Face Mesh initialized!\n"
     ]
    }
   ],
   "source": [
    "# ‚û§ Initialize Face Mesh with default parameters\n",
    "mp_face = mp.solutions.face_mesh\n",
    "face_mesh = mp_face.FaceMesh(\n",
    "    max_num_faces=2,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Drawing utilities\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "print(\"MediaPipe Face Mesh initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a277e7a",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üì∏ Real-Time Face Mesh Detection (Webcam)</h2>\n",
    "\n",
    "This code uses your **system webcam** to capture video frames and draw face landmarks in real-time.  \n",
    "Press **ESC** to exit the window.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb75c8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚û§ Real-time Face Mesh Detection\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Draw tesselation (triangular mesh)\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=frame,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face.FACEMESH_TESSELATION,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=drawing_spec\n",
    "            )\n",
    "            # Draw contours\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=frame,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face.FACEMESH_CONTOURS,\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=drawing_spec\n",
    "            )\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Face Landmarks\", frame)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e86a5f",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üìú Reference: Sir‚Äôs Original Combined Script</h2>\n",
    "\n",
    "Below is the reference code where both **Face** and **Hand** landmarks were drawn using MediaPipe Holistic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af3f7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "capture = cv2.VideoCapture(0)\n",
    "previousTime = 0\n",
    "currentTime = 0\n",
    "\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = holistic_model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "    currentTime = time.time()\n",
    "    fps = 1 / (currentTime - previousTime)\n",
    "    previousTime = currentTime\n",
    "    cv2.putText(image, f\"{int(fps)} FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa581e72",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üßæ Summary</h2>\n",
    "\n",
    "| Topic | Covered |\n",
    "|--------|----------|\n",
    "| Face Mesh Overview | ‚úÖ |\n",
    "| Real-time Webcam Detection | ‚úÖ |\n",
    "| Drawing Tesselation & Contours | ‚úÖ |\n",
    "| Combined Reference Code | ‚úÖ |\n",
    "\n",
    "Next up: **Pose Landmarks Detection with MediaPipe**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
