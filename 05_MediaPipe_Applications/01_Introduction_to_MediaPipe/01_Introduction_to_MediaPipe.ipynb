{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bbc9f14",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üìò Introduction to MediaPipe</h2>\n",
    "\n",
    "MediaPipe is an open-source, cross-platform framework developed by **Google** for building **real-time, on-device perception pipelines** using Machine Learning.  \n",
    "It provides ready-to-use solutions for tasks like **hand tracking, face mesh, pose detection, and 3D object detection**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f0598",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üß© Why MediaPipe?</h2>\n",
    "\n",
    "- üöÄ Cross-platform (Python, Android, iOS, Web, C++)  \n",
    "- üß† Optimized for **real-time on-device performance**  \n",
    "- üîß Ready-made **ML pipelines** ‚Äî no model training required  \n",
    "- ü§ù Integrates easily with **OpenCV**, **TensorFlow Lite**, and **Deep Learning projects**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94838815",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üèóÔ∏è MediaPipe Architecture</h2>\n",
    "\n",
    "MediaPipe pipelines are made of **graphs** built from small processing units called **calculators**.\n",
    "\n",
    "**Terminology:**  \n",
    "- **Calculator** ‚Üí Performs a specific task (like inference or drawing).  \n",
    "- **Graph** ‚Üí A network of calculators connected together to process data.  \n",
    "\n",
    "**Example flow:**  \n",
    "üì∏ Camera ‚Üí üßÆ Graph (Detection + Tracking) ‚Üí üéØ Landmarks on Frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4ec790",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">‚öôÔ∏è Installation</h2>\n",
    "\n",
    "You can install MediaPipe and OpenCV in any Python environment (VSCode, Colab, or Jupyter).  \n",
    "Run the following commands in your terminal or notebook cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a1eb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚û§ Install necessary libraries\n",
    "# (Run this in terminal or a notebook cell)\n",
    "# For VSCode users: use `pip install` in your virtual environment\n",
    "\n",
    "# !pip install mediapipe opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae554fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚û§ Verify installation\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "\n",
    "print(\"MediaPipe version:\", mp.__version__)\n",
    "print(\"OpenCV version:\", cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c904f",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üß† Key Components of MediaPipe</h2>\n",
    "\n",
    "| Component | Description | Example |\n",
    "|------------|--------------|----------|\n",
    "| **Solutions** | Ready-made ML pipelines | `mp.solutions.hands` |\n",
    "| **Graphs** | Connect multiple calculators to form pipelines | Hand Tracking Graph |\n",
    "| **Calculators** | Single operation (like image conversion or inference) | `ImageToTensorCalculator` |\n",
    "| **Landmarks** | Detected keypoints (x, y, z) | Hand, Face, Pose joints |\n",
    "| **Drawing Utils** | Helper tools to visualize results | `mp.solutions.drawing_utils` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95fd367",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üß© Common MediaPipe Solutions</h2>\n",
    "\n",
    "| Solution | Description | Typical Use |\n",
    "|-----------|--------------|--------------|\n",
    "| **Hands** | Detects and tracks hand landmarks | Gesture control, sign language |\n",
    "| **Face Mesh** | 468 facial landmarks | Beauty filters, emotion tracking |\n",
    "| **Pose** | 33 body landmarks | Fitness, motion capture |\n",
    "| **Objectron** | 3D bounding boxes | AR/VR, 3D object detection |\n",
    "| **Holistic** | Combines Hands + Face + Pose | Full-body landmark tracking |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd24f3c8",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üß∞ Integration with OpenCV</h2>\n",
    "\n",
    "MediaPipe often works **with OpenCV** to handle video frames, color conversion, and rendering.  \n",
    "Below is a sample code snippet that captures webcam video and applies a MediaPipe pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ebf40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    # Convert frame to RGB (MediaPipe expects RGB input)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(rgb_frame)\n",
    "\n",
    "    # Draw hand landmarks\n",
    "    if result.multi_hand_landmarks:\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    cv2.imshow(\"MediaPipe Hand Demo\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC to exit\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c800fc07",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üß© Typical Workflow</h2>\n",
    "\n",
    "1. Import the required **MediaPipe solution**.  \n",
    "2. Initialize the model.  \n",
    "3. Pass input image/video frames.  \n",
    "4. Process and get results.  \n",
    "5. Visualize landmarks with drawing utilities.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8738df1",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üß≠ Wrap-Up Summary</h2>\n",
    "\n",
    "| Topic | Covered |\n",
    "|--------|----------|\n",
    "| Overview & Purpose | ‚úÖ |\n",
    "| Architecture (Graphs & Calculators) | ‚úÖ |\n",
    "| Installation | ‚úÖ |\n",
    "| Components & Solutions | ‚úÖ |\n",
    "| OpenCV Integration | ‚úÖ |\n",
    "| Hands-on Example | ‚úÖ |\n",
    "\n",
    "Next: proceed to **02_Hand_Landmarks_Detection/** where we‚Äôll build a practical real-time tracker.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
