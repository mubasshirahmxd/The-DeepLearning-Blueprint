{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7222d5",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">ü§ñ Holistic Model & Integration (MediaPipe)</h2>\n",
    "\n",
    "This notebook demonstrates MediaPipe's **Holistic** solution ‚Äî a unified on-device pipeline that combines **Face Mesh**, **Hands**, and **Pose** detection into one real-time system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f88798",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üß† Theory Overview</h2>\n",
    "\n",
    "The Holistic model integrates multiple sub-models (face, hands, pose) to provide a full-body and face tracking solution. It outputs landmarks for face (468 points), hands (21 each), and pose (33 points). Typical applications include fitness coaching, AR filters, gesture control, and motion analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690a97a",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">‚öôÔ∏è Setup and Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3959ff42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78070b69",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üíª Initialize Holistic Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d646b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Holistic model initialized!\n"
     ]
    }
   ],
   "source": [
    "# ‚û§ Initialize Holistic model\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "print('Holistic model initialized!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50ded67",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üì∏ Real-Time Holistic Detection (Webcam)</h2>\n",
    "\n",
    "Run the block below to start webcam-based Holistic detection. Press **ESC** to exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd00813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚û§ Real-time holistic detection\n",
    "cap = cv2.VideoCapture(0)\n",
    "prev_time = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print('Failed to capture frame.')\n",
    "        break\n",
    "\n",
    "    frame = cv2.resize(frame, (960, 720))\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    rgb.flags.writeable = False\n",
    "    results = holistic_model.process(rgb)\n",
    "    rgb.flags.writeable = True\n",
    "\n",
    "    image = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Draw face\n",
    "    if results.face_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION)\n",
    "        mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)\n",
    "\n",
    "    # Draw hands\n",
    "    if results.right_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    if results.left_hand_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "    # Draw pose\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)\n",
    "\n",
    "    # FPS\n",
    "    curr_time = time.time()\n",
    "    fps = 1 / (curr_time - prev_time) if prev_time else 0\n",
    "    prev_time = curr_time\n",
    "    cv2.putText(image, f\"FPS: {int(fps)}\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "    cv2.imshow('Holistic Detection', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd85a3",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üìú Sir‚Äôs Reference Code</h2>\n",
    "\n",
    "Below is your instructor's original Holistic demo (included for comparison)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c82e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sir's Holistic reference (shortened)\n",
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "capture = cv2.VideoCapture(0)\n",
    "previousTime = 0\n",
    "\n",
    "while capture.isOpened():\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = holistic_model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "    currentTime = time.time()\n",
    "    fps = 1 / (currentTime - previousTime)\n",
    "    previousTime = currentTime\n",
    "    cv2.putText(image, str(int(fps)) + ' FPS', (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Facial and Hand Landmarks', image)\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb50688",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">üßæ Summary</h2>\n",
    "\n",
    "| Topic | Covered |\n",
    "|--------|----------|\n",
    "| Holistic Overview | ‚úÖ |\n",
    "| Real-time Face + Hands + Pose | ‚úÖ |\n",
    "| FPS Display | ‚úÖ |\n",
    "| Sir's Reference Included | ‚úÖ |\n",
    "\n",
    "Next: Advanced 3D Face Transforms (if your sir covers it)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
