{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e060d9",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Convolutional Neural Network (CNN) Architecture</h2>\n",
    "\n",
    "**Author:** Mubasshir Ahmed  \n",
    "**Module:** Deep Learning ‚Äî FSDS  \n",
    "**Notebook:** 02_CNN_Architecture  \n",
    "**Objective:** Learn the structure, data flow, and purpose of each layer in a Convolutional Neural Network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3864f767",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>1Ô∏è‚É£ CNN Layer Flow Overview</h3>\n",
    "\n",
    "The general flow of a CNN architecture is as follows:\n",
    "\n",
    "```\n",
    "Input ‚Üí Convolution ‚Üí Activation ‚Üí Pooling ‚Üí Flatten ‚Üí Fully Connected ‚Üí Output\n",
    "```\n",
    "\n",
    "Each stage transforms the data into a more abstract and meaningful representation.\n",
    "\n",
    "| Stage | Purpose |\n",
    "|--------|----------|\n",
    "| Input | Accepts image data |\n",
    "| Convolution | Extracts patterns/features |\n",
    "| Activation | Adds non-linearity |\n",
    "| Pooling | Reduces dimensionality |\n",
    "| Flatten | Converts 2D ‚Üí 1D |\n",
    "| Fully Connected | Combines features |\n",
    "| Output | Predicts final class |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c90f3e",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>2Ô∏è‚É£ Input Layer</h3>\n",
    "\n",
    "- **Input:** The image itself (height √ó width √ó channels).  \n",
    "- RGB images have **3 channels** ‚Üí Red, Green, Blue.  \n",
    "- Example: (64√ó64√ó3) = 12,288 pixel values per image.  \n",
    "- Values are normalized between 0 and 1 for stable training.\n",
    "\n",
    "**Shape Convention (TensorFlow):**\n",
    "```\n",
    "(batch_size, height, width, channels)\n",
    "```\n",
    "Example: (32, 64, 64, 3) ‚Üí 32 images of size 64√ó64 with 3 channels each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13af3f54",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>3Ô∏è‚É£ Convolution Layer</h3>\n",
    "\n",
    "The **Convolution Layer** is the heart of CNNs.\n",
    "\n",
    "It applies small learnable filters (kernels) that slide over the input image and compute dot products with local pixel regions.\n",
    "\n",
    "**Mathematical Definition:**\n",
    "\\[ (I * K)(x, y) = \\sum_i \\sum_j I(x+i, y+j)K(i,j) \\]\n",
    "\n",
    "| Term | Meaning |\n",
    "|------|----------|\n",
    "| I | Input Image |\n",
    "| K | Kernel/Filter |\n",
    "| * | Convolution operation |\n",
    "\n",
    "Each filter produces a **feature map** representing where a certain feature appears.\n",
    "\n",
    "**Output Size Formula:**\n",
    "\\[ O = \\frac{(W - F + 2P)}{S} + 1 \\]\n",
    "where:  \n",
    "- W = input width  \n",
    "- F = filter size  \n",
    "- P = padding  \n",
    "- S = stride\n",
    "\n",
    "**Example:**  \n",
    "Input: 32√ó32√ó3 ‚Üí Filter: 3√ó3 ‚Üí Stride: 1 ‚Üí Output: 30√ó30√ó8 (8 filters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850f313",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>4Ô∏è‚É£ Activation Layer (ReLU)</h3>\n",
    "\n",
    "After convolution, we apply an **activation function** to introduce non-linearity.\n",
    "\n",
    "Most common: **ReLU (Rectified Linear Unit)**\n",
    "\n",
    "\\[ f(x) = \\max(0, x) \\]\n",
    "\n",
    "ReLU allows CNNs to model complex functions while reducing vanishing gradient issues.\n",
    "\n",
    "| Activation | Used In | Range |\n",
    "|-------------|----------|--------|\n",
    "| ReLU | Hidden layers | [0, ‚àû) |\n",
    "| Leaky ReLU | Hidden layers | (-‚àû, ‚àû) |\n",
    "| Softmax | Output (multi-class) | (0, 1) |\n",
    "| Sigmoid | Output (binary) | (0, 1) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1332b8",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>5Ô∏è‚É£ Pooling Layer</h3>\n",
    "\n",
    "Pooling layers reduce the spatial dimensions of feature maps, keeping only the most important information.\n",
    "\n",
    "**Types of Pooling:**\n",
    "- **Max Pooling:** Retains the maximum value in each region.\n",
    "- **Average Pooling:** Takes the average of the region.\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Input: 4√ó4 ‚Üí Max Pooling(2√ó2) ‚Üí Output: 2√ó2\n",
    "```\n",
    "Pooling provides:\n",
    "‚úÖ Translation invariance  \n",
    "‚úÖ Reduced computation  \n",
    "‚úÖ Lower overfitting risk\n",
    "\n",
    "Pooling window and stride determine how much reduction occurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7db646",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>6Ô∏è‚É£ Flatten Layer</h3>\n",
    "\n",
    "The Flatten layer converts 2D feature maps into a 1D vector.\n",
    "\n",
    "**Example:**\n",
    "Feature map: (8 √ó 8 √ó 32) ‚Üí Flattened: 2048 neurons (8√ó8√ó32).\n",
    "\n",
    "This prepares the data for Dense (Fully Connected) layers that expect 1D input.\n",
    "\n",
    "**Analogy:**  \n",
    "> Flattening is like unrolling a folded map into a single line of pixels for the final decision-making process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242954eb",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>7Ô∏è‚É£ Fully Connected (Dense) Layers</h3>\n",
    "\n",
    "These layers are similar to those in an Artificial Neural Network (ANN).\n",
    "\n",
    "- Combine all learned features to form final decisions.  \n",
    "- Each neuron is connected to all neurons in the previous layer.  \n",
    "- Use **ReLU** in hidden Dense layers for speed and performance.  \n",
    "- Use **Sigmoid** or **Softmax** in the final output layer.\n",
    "\n",
    "| Layer | Activation | Description |\n",
    "|--------|-------------|--------------|\n",
    "| Dense(128) | ReLU | Hidden layer |\n",
    "| Dense(1) | Sigmoid | Binary classification output |\n",
    "| Dense(10) | Softmax | Multi-class output |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb1a50b",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>8Ô∏è‚É£ Output Layer</h3>\n",
    "\n",
    "The Output Layer produces final predictions.\n",
    "\n",
    "| Problem Type | Activation | Output Example |\n",
    "|---------------|-------------|----------------|\n",
    "| Binary Classification | Sigmoid | 1 neuron |\n",
    "| Multi-class Classification | Softmax | N neurons (one per class) |\n",
    "| Regression | Linear | 1 neuron |\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Dense(1, activation='sigmoid') ‚Üí predicts churn (0/1)\n",
    "Dense(10, activation='softmax') ‚Üí predicts image category (0‚Äì9)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d86f1",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>9Ô∏è‚É£ Example: Mini CNN Architecture</h3>\n",
    "\n",
    "Example architecture for an image classification problem:\n",
    "\n",
    "```python\n",
    "Input (64x64x3)\n",
    "‚Üí Conv2D(32, (3,3), activation='relu')\n",
    "‚Üí MaxPooling2D(2,2)\n",
    "‚Üí Conv2D(64, (3,3), activation='relu')\n",
    "‚Üí MaxPooling2D(2,2)\n",
    "‚Üí Flatten()\n",
    "‚Üí Dense(128, activation='relu')\n",
    "‚Üí Dense(1, activation='sigmoid')\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- Filters increase as we go deeper (32 ‚Üí 64 ‚Üí 128).\n",
    "- Spatial size decreases after pooling.\n",
    "- Fully connected layers combine high-level features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e777f27",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>üîü CNN Architecture Design Tips</h3>\n",
    "\n",
    "‚úÖ Use **small filters (3√ó3)** ‚Äî faster and effective.  \n",
    "‚úÖ Double filter count after each pooling layer.  \n",
    "‚úÖ Add **Dropout** (0.3‚Äì0.5) to prevent overfitting.  \n",
    "‚úÖ Apply **BatchNormalization** after Conv layers.  \n",
    "‚úÖ Use **ReLU** for hidden layers, **Sigmoid/Softmax** for output.  \n",
    "‚úÖ Use **Adam** optimizer for faster convergence.\n",
    "\n",
    "**Pro tip:** For complex datasets, start with pre-trained models (VGG16, ResNet, MobileNet) and fine-tune them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0333ae",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>‚úÖ Summary ‚Äî CNN Architecture in a Nutshell</h3>\n",
    "\n",
    "- CNNs are made up of **Convolution + Activation + Pooling** blocks followed by **Dense layers**.  \n",
    "- Each layer type has a distinct purpose.  \n",
    "- CNNs gradually reduce spatial size while increasing feature depth.  \n",
    "- The architecture forms the foundation for computer vision models like ResNet, VGG, Inception, and EfficientNet.\n",
    "\n",
    "**Next Notebook:** `03_Convolution_Pooling_Operations.ipynb`  \n",
    "We‚Äôll mathematically visualize convolution, stride, padding, and pooling operations with examples.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
