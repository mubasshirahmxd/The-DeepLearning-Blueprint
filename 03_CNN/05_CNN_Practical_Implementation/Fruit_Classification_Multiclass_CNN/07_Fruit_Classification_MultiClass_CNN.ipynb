{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26ccbc36",
   "metadata": {},
   "source": [
    "# ðŸŽ Fruit Classification â€” Multi-Class CNN using TensorFlow & Keras\n",
    "\n",
    "This Colab-ready notebook trains a simple CNN to classify **Apple**, **Banana**, and **Orange** images. It includes data loading (Drive), training with callbacks, evaluation, single-image prediction, and TFLite export.\n",
    "\n",
    "> **Note:** Run this in Google Colab. Mount your Drive and place your dataset in `MyDrive/fruits-dataset/` with `train/` and `validation/` subfolders, each containing `apple/`, `banana/`, and `orange/` folders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a53a45",
   "metadata": {},
   "source": [
    "## 1) Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8609fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (Colab)\n",
    "from google.colab import drive, files\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, os, itertools\n",
    "\n",
    "print('# âž¤ TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322dffd0",
   "metadata": {},
   "source": [
    "## 2) Data Loading & Preprocessing\n",
    "\n",
    "Set paths to your dataset in Drive. The directory structure should be:\n",
    "```\n",
    "fruits-dataset/\n",
    "  train/\n",
    "    apple/\n",
    "    banana/\n",
    "    orange/\n",
    "  validation/\n",
    "    apple/\n",
    "    banana/\n",
    "    orange/\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b469efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (edit if your location differs)\n",
    "train_dir = '/content/drive/MyDrive/fruits-dataset/train'\n",
    "val_dir   = '/content/drive/MyDrive/fruits-dataset/validation'\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = (100, 100)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(train_dir,\n",
    "                                              target_size=IMG_SIZE,\n",
    "                                              batch_size=BATCH_SIZE,\n",
    "                                              class_mode='categorical',\n",
    "                                              shuffle=True)\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(val_dir,\n",
    "                                          target_size=IMG_SIZE,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          class_mode='categorical',\n",
    "                                          shuffle=False)\n",
    "\n",
    "print('\\n# âž¤ Classes found (label -> index):', train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93111ba4",
   "metadata": {},
   "source": [
    "## 3) Build the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3407fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(train_gen.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cbd619",
   "metadata": {},
   "source": [
    "## 4) Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('/content/drive/MyDrive/fruit_best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d6b834",
   "metadata": {},
   "source": [
    "## 5) Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 25\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48686589",
   "metadata": {},
   "source": [
    "## 6) Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0a4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1878fc75",
   "metadata": {},
   "source": [
    "## 7) Evaluation â€” Confusion Matrix & Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set\n",
    "val_gen.reset()\n",
    "preds = model.predict(val_gen, verbose=1)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = val_gen.classes\n",
    "\n",
    "labels = list(val_gen.class_indices.keys())\n",
    "\n",
    "# Classification report\n",
    "print('\\nClassification Report:\\n')\n",
    "print(classification_report(y_true, y_pred, target_names=labels))\n",
    "\n",
    "# Confusion matrix heatmap\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(labels))\n",
    "plt.xticks(tick_marks, labels, rotation=45)\n",
    "plt.yticks(tick_marks, labels)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment='center',\n",
    "             color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc370a",
   "metadata": {},
   "source": [
    "## 8) Single Image Prediction (Upload an image in Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b011a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "uploaded = files.upload()\n",
    "img_path = list(uploaded.keys())[0]\n",
    "\n",
    "img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "plt.imshow(img); plt.axis('off'); plt.show()\n",
    "\n",
    "x = image.img_to_array(img) / 255.0\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "pred = model.predict(x)\n",
    "label_map = {v:k for k,v in train_gen.class_indices.items()}\n",
    "pred_label = label_map[np.argmax(pred)]\n",
    "print(f'Predicted: {pred_label} | Confidence: {np.max(pred)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35184855",
   "metadata": {},
   "source": [
    "## 9) Export Model to TensorFlow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eaa8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Keras model (best already saved by checkpoint)\n",
    "model.save('/content/drive/MyDrive/fruit_model_final.h5')\n",
    "\n",
    "# Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open('fruit_model_android.tflite', 'wb').write(tflite_model)\n",
    "\n",
    "# Download the TFLite file\n",
    "files.download('fruit_model_android.tflite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9454d2",
   "metadata": {},
   "source": [
    "## 10) Summary\n",
    "\n",
    "- Trained a 3-class CNN (Apple, Banana, Orange).\n",
    "- Added callbacks and evaluation metrics.\n",
    "- Exported model to `.tflite` for Android deployment.\n",
    "\n",
    "Good luck â€” run this in Colab and let me know if you want optimizations or smaller model variants for mobile."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
