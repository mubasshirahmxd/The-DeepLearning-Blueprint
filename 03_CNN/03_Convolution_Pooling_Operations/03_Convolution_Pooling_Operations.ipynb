{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7724cc60",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Convolution and Pooling Operations in CNN</h2>\n",
    "\n",
    "**Author:** Mubasshir Ahmed  \n",
    "**Module:** Deep Learning ‚Äî FSDS  \n",
    "**Notebook:** 03_Convolution_Pooling_Operations  \n",
    "**Objective:** Understand the mathematical and visual intuition behind convolution, padding, stride, and pooling operations in CNNs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1cc572",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>1Ô∏è‚É£ Introduction</h3>\n",
    "\n",
    "The strength of a Convolutional Neural Network (CNN) lies in two fundamental operations:\n",
    "\n",
    "1. **Convolution** ‚Äî Feature extraction (edges, patterns, textures).  \n",
    "2. **Pooling** ‚Äî Dimensionality reduction while retaining essential features.\n",
    "\n",
    "Together, they enable CNNs to detect meaningful features and reduce computational cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8aa9cc4",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>2Ô∏è‚É£ Convolution Operation ‚Äî Core Idea</h3>\n",
    "\n",
    "A **convolution** operation slides a small matrix (called a *filter* or *kernel*) over the input image.\n",
    "\n",
    "At each position, it performs an **element-wise multiplication** between the filter and the image patch and sums the results to form a new pixel in the output feature map.\n",
    "\n",
    "**Mathematical Representation:**\n",
    "\\[ (I * K)(x, y) = \\sum_i \\sum_j I(x+i, y+j)K(i,j) \\]\n",
    "\n",
    "| Term | Meaning |\n",
    "|------|----------|\n",
    "| I | Input image |\n",
    "| K | Kernel (filter) |\n",
    "| (x, y) | Position in the output feature map |\n",
    "\n",
    "**Intuition:**  \n",
    "Each filter learns to recognize a specific pattern such as vertical edges, horizontal lines, or color gradients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5210c0",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>3Ô∏è‚É£ Example of Convolution (Matrix View)</h3>\n",
    "\n",
    "Let‚Äôs take a **3√ó3 kernel** and a **5√ó5 image** as an example.\n",
    "\n",
    "**Input Image (5√ó5):**\n",
    "```\n",
    "1  1  1  0  0\n",
    "0  1  1  1  0\n",
    "0  0  1  1  1\n",
    "0  0  1  1  0\n",
    "0  1  1  0  0\n",
    "```\n",
    "\n",
    "**Kernel (3√ó3):**\n",
    "```\n",
    "1  0  1\n",
    "0  1  0\n",
    "1  0  1\n",
    "```\n",
    "\n",
    "Now, slide the kernel over the image ‚Üí multiply element-wise ‚Üí sum results.\n",
    "\n",
    "**First convolution result (top-left corner):**\n",
    "```\n",
    "(1√ó1) + (1√ó0) + (1√ó1) +\n",
    "(0√ó0) + (1√ó1) + (1√ó0) +\n",
    "(0√ó1) + (0√ó0) + (1√ó1) = 4\n",
    "```\n",
    "\n",
    "Continue sliding ‚Üí final **feature map (3√ó3)**.\n",
    "\n",
    "This operation detects **patterns** such as edges or textures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e7d648",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>4Ô∏è‚É£ Stride in Convolution</h3>\n",
    "\n",
    "**Stride** defines how much the filter moves after each operation.\n",
    "\n",
    "- **Stride = 1:** Filter moves 1 pixel ‚Üí High resolution output.  \n",
    "- **Stride = 2:** Filter moves 2 pixels ‚Üí Smaller output.\n",
    "\n",
    "**Formula for output size:**\n",
    "\\[ O = \\frac{(W - F)}{S} + 1 \\]\n",
    "\n",
    "Example:  \n",
    "Input size = 5, Filter size = 3, Stride = 1 ‚Üí Output = 3  \n",
    "Input size = 5, Filter size = 3, Stride = 2 ‚Üí Output = 2\n",
    "\n",
    "**Effect:** Larger stride ‚Üí fewer computations but more information loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efc1df2",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>5Ô∏è‚É£ Padding in Convolution</h3>\n",
    "\n",
    "When a filter slides across an image, **border pixels** are used fewer times than center pixels.\n",
    "\n",
    "To avoid losing edge information, we use **Padding**.\n",
    "\n",
    "| Padding Type | Description | Output Size |\n",
    "|---------------|--------------|--------------|\n",
    "| **Valid** | No padding ‚Äî output shrinks | Smaller |\n",
    "| **Same** | Adds zeros around image ‚Äî keeps same size | Same as input |\n",
    "\n",
    "**Example:**  \n",
    "Input: 5√ó5, Filter: 3√ó3, Stride: 1  \n",
    "- Valid ‚Üí Output: 3√ó3  \n",
    "- Same ‚Üí Output: 5√ó5\n",
    "\n",
    "Padding ensures that important edge details aren‚Äôt lost during convolution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f9f09a",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>6Ô∏è‚É£ Feature Maps ‚Äî The Output of Convolution</h3>\n",
    "\n",
    "Each convolution operation produces a **feature map**.\n",
    "\n",
    "If multiple filters are used (e.g., 32 filters), each detects a different pattern.\n",
    "\n",
    "| Filter | Detects |\n",
    "|---------|----------|\n",
    "| Filter 1 | Horizontal edges |\n",
    "| Filter 2 | Vertical edges |\n",
    "| Filter 3 | Color gradients |\n",
    "\n",
    "Stacking all these maps along the depth dimension gives the CNN its **depth (number of channels)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f343d5e",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>7Ô∏è‚É£ Pooling Operation ‚Äî Reducing Dimensions</h3>\n",
    "\n",
    "Pooling is used to reduce the size of feature maps while keeping key information.\n",
    "\n",
    "Types:\n",
    "1. **Max Pooling** ‚Üí Keeps the maximum value in each window.  \n",
    "2. **Average Pooling** ‚Üí Takes the average of values in the window.\n",
    "\n",
    "**Example (2√ó2 Max Pooling):**\n",
    "\n",
    "Input feature map:\n",
    "```\n",
    "1  3  2  4\n",
    "5  6  7  8\n",
    "3  2  1  0\n",
    "1  2  3  4\n",
    "```\n",
    "\n",
    "Pooling result:\n",
    "```\n",
    "6  8\n",
    "3  4\n",
    "```\n",
    "\n",
    "Reduces dimension by half (4√ó4 ‚Üí 2√ó2) while keeping dominant features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91320c02",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>8Ô∏è‚É£ Pooling Parameters</h3>\n",
    "\n",
    "| Parameter | Description | Typical Values |\n",
    "|------------|-------------|----------------|\n",
    "| **Pool Size** | Window size | (2√ó2) |\n",
    "| **Stride** | Step size of window | 2 |\n",
    "| **Type** | Max / Average | Max |\n",
    "| **Padding** | Border handling | ‚Äòsame‚Äô, ‚Äòvalid‚Äô |\n",
    "\n",
    "Pooling helps prevent overfitting and reduces computation cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7fffdd",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>9Ô∏è‚É£ Combining Convolution + Pooling</h3>\n",
    "\n",
    "CNNs usually combine these two steps repeatedly:\n",
    "\n",
    "```\n",
    "Conv2D ‚Üí ReLU ‚Üí Pooling ‚Üí Conv2D ‚Üí ReLU ‚Üí Pooling ‚Üí Flatten ‚Üí Dense\n",
    "```\n",
    "\n",
    "- Each convolution extracts **more complex features**.  \n",
    "- Pooling compresses information.  \n",
    "- Together, they help CNNs achieve **translation invariance** (recognizing objects anywhere in the image).\n",
    "\n",
    "**Analogy:**  \n",
    "> Think of convolution as ‚Äúlooking closely‚Äù and pooling as ‚Äúsummarizing what you saw.‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814de2d4",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>üîü Visual Summary</h3>\n",
    "\n",
    "| Stage | Input Size | Operation | Output Size | Purpose |\n",
    "|--------|-------------|------------|--------------|----------|\n",
    "| Input | 32√ó32√ó3 | ‚Äî | 32√ó32√ó3 | Raw image |\n",
    "| Conv2D | 32√ó32√ó3 | Filters (3√ó3√ó8) | 30√ó30√ó8 | Feature extraction |\n",
    "| Pooling | 30√ó30√ó8 | 2√ó2 MaxPool | 15√ó15√ó8 | Downsample |\n",
    "| Conv2D | 15√ó15√ó8 | Filters (3√ó3√ó16) | 13√ó13√ó16 | Deeper features |\n",
    "| Pooling | 13√ó13√ó16 | 2√ó2 MaxPool | 6√ó6√ó16 | Final compressed map |\n",
    "\n",
    "CNNs repeat this pattern multiple times before flattening into a Dense layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455998d8",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>‚úÖ Summary ‚Äî Core Takeaways</h3>\n",
    "\n",
    "- **Convolution** extracts local spatial features.  \n",
    "- **Stride** controls step size and output resolution.  \n",
    "- **Padding** preserves spatial dimensions and edge info.  \n",
    "- **Pooling** reduces size and complexity.  \n",
    "- Combined, they create hierarchical feature maps ‚Üí edges ‚Üí shapes ‚Üí objects.\n",
    "\n",
    "**Next Notebook:** `04_Activation_and_Regularization_in_CNN.ipynb`  \n",
    "We‚Äôll learn how CNNs use activations, dropout, and batch normalization to improve performance and stability.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
