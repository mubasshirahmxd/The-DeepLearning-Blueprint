{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a407ba",
   "metadata": {},
   "source": [
    "<h2 style=\"text-align:center;\">Loss Functions and Optimizers ‚Äî Deep Learning</h2>\n",
    "\n",
    "**Author:** Mubasshir Ahmed  \n",
    "**Module:** Deep Learning ‚Äî FSDS  \n",
    "**Notebook:** 05_Loss_Functions_&_Optimizers  \n",
    "**Objective:** Understand how neural networks measure errors (loss functions) and how they update weights efficiently (optimizers).\n",
    "\n",
    "---\n",
    "\n",
    "Every learning model needs two critical components:\n",
    "\n",
    "1. A **Loss Function** ‚Äî tells the model *how wrong it is*.  \n",
    "2. An **Optimizer** ‚Äî tells the model *how to get better* by updating weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147bd79",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>1Ô∏è‚É£ What is a Loss Function?</h3>\n",
    "\n",
    "A **Loss Function** (also called **Cost Function**) measures the difference between predicted output (\\( \\hat{y} \\)) and actual output (\\( y \\)).\n",
    "\n",
    "The goal of training a neural network is to **minimize the loss** ‚Äî i.e., make predictions as close as possible to the truth.\n",
    "\n",
    "**Formula (general):**\n",
    "\\[ L = f(y, \\hat{y}) \\]\n",
    "\n",
    "Low loss ‚Üí better performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad965f1",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>2Ô∏è‚É£ Why Do We Need a Loss Function?</h3>\n",
    "\n",
    "- It provides a **numerical feedback** signal to guide learning.  \n",
    "- Without loss, the optimizer won‚Äôt know how to adjust weights.  \n",
    "- Each iteration, the model computes loss ‚Üí optimizer uses it to improve.\n",
    "\n",
    "**Analogy:**  \n",
    "> Imagine practicing darts ‚Äî the loss tells you *how far you missed the target*, and you adjust your throw accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f002a3",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>3Ô∏è‚É£ Common Loss Functions for Regression</h3>\n",
    "\n",
    "| Loss | Formula | Description |\n",
    "|-------|----------|-------------|\n",
    "| **Mean Absolute Error (MAE)** | \\( L = \\frac{1}{n}\\sum |y - \\hat{y}| \\) | Measures average absolute difference. |\n",
    "| **Mean Squared Error (MSE)** | \\( L = \\frac{1}{n}\\sum (y - \\hat{y})^2 \\) | Penalizes larger errors more. |\n",
    "| **Huber Loss** | Hybrid of MAE & MSE | Robust to outliers, smoother gradient. |\n",
    "\n",
    "**When to use:**\n",
    "- **MAE:** When outliers exist (robust).  \n",
    "- **MSE:** When you want stronger penalty on large errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c048d615",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>4Ô∏è‚É£ Common Loss Functions for Classification</h3>\n",
    "\n",
    "| Loss | Used For | Formula |\n",
    "|------|-----------|----------|\n",
    "| **Binary Cross-Entropy (BCE)** | Binary classification | \\( L = -[y\\log(\\hat{y}) + (1-y)\\log(1-\\hat{y})] \\) |\n",
    "| **Categorical Cross-Entropy (CCE)** | Multi-class | \\( L = -\\sum y_i \\log(\\hat{y_i}) \\) |\n",
    "| **Sparse Categorical Cross-Entropy** | Multi-class (integer labels) | Same as CCE but labels are integers. |\n",
    "\n",
    "**Interpretation:**\n",
    "- Measures dissimilarity between true labels and predicted probabilities.  \n",
    "- Ideal when output activations = Sigmoid or Softmax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b070e3a",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>5Ô∏è‚É£ The Role of Optimizers</h3>\n",
    "\n",
    "An **Optimizer** adjusts the weights and biases based on the gradients computed during backpropagation.\n",
    "\n",
    "It determines *how fast* and *how effectively* the model learns.\n",
    "\n",
    "**Optimization Goal:**\n",
    "\\[ \\min_W L(W) \\]\n",
    "where \\( L(W) \\) is the loss as a function of model weights.\n",
    "\n",
    "Different optimizers handle gradient updates differently to improve convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5316e0",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>6Ô∏è‚É£ Gradient Descent ‚Äî The Foundation</h3>\n",
    "\n",
    "**Gradient Descent** is the core concept behind all optimizers.\n",
    "\n",
    "**Update Rule:**\n",
    "\\[ W_{new} = W_{old} - \\eta \\frac{\\partial L}{\\partial W} \\]\n",
    "\n",
    "Where:\n",
    "- \\( \\eta \\): learning rate  \n",
    "- \\( \\frac{\\partial L}{\\partial W} \\): gradient of loss w.r.t weight  \n",
    "\n",
    "**Goal:** Move towards the minimum loss value.\n",
    "\n",
    "| Type | Description |\n",
    "|------|--------------|\n",
    "| **Batch Gradient Descent** | Uses entire dataset per update (stable but slow) |\n",
    "| **Stochastic Gradient Descent (SGD)** | Updates weights per sample (fast but noisy) |\n",
    "| **Mini-Batch Gradient Descent** | Uses small batches (balances speed and stability) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c60a9de",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>7Ô∏è‚É£ Advanced Optimizers</h3>\n",
    "\n",
    "| Optimizer | Description | Key Idea |\n",
    "|------------|--------------|-----------|\n",
    "| **Momentum** | Accelerates gradient descent by adding momentum from previous steps | Avoids local minima |\n",
    "| **AdaGrad** | Adjusts learning rate per parameter based on gradient history | Good for sparse data |\n",
    "| **RMSProp** | Uses moving average of squared gradients | Handles non-stationary objectives well |\n",
    "| **Adam (Adaptive Moment Estimation)** | Combines Momentum + RMSProp | Most popular choice |\n",
    "| **AdaDelta / Adamax** | Variants improving numerical stability | Specialized use cases |\n",
    "\n",
    "**Adam Update Rule (simplified):**\n",
    "\\[ m_t = \\beta_1 m_{t-1} + (1-\\beta_1)g_t \\]\n",
    "\\[ v_t = \\beta_2 v_{t-1} + (1-\\beta_2)g_t^2 \\]\n",
    "\\[ W = W - \\eta \\frac{m_t}{\\sqrt{v_t} + \\epsilon} \\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbe0e5c",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>8Ô∏è‚É£ Choosing the Right Optimizer</h3>\n",
    "\n",
    "| Task | Recommended Optimizer |\n",
    "|------|--------------------------|\n",
    "| Simple ANN or CNN | **Adam** (default) |\n",
    "| Large datasets, online learning | **SGD with Momentum** |\n",
    "| Noisy gradients | **RMSProp** |\n",
    "| NLP embeddings, sparse data | **AdaGrad** |\n",
    "| Reinforcement learning | **Adam / RMSProp** |\n",
    "\n",
    "**Tip:** Start with Adam; tune learning rate if training oscillates or converges too slowly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3478706f",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>9Ô∏è‚É£ Relationship Between Loss Function and Optimizer</h3>\n",
    "\n",
    "The **loss function** defines *what to minimize*, while the **optimizer** defines *how to minimize it*.\n",
    "\n",
    "| Component | Function |\n",
    "|------------|-----------|\n",
    "| Loss Function | Quantifies model error |\n",
    "| Optimizer | Updates weights to reduce loss |\n",
    "\n",
    "Together, they form the **training loop backbone**:\n",
    "\n",
    "1. Forward Pass ‚Üí Compute Predictions  \n",
    "2. Compute Loss  \n",
    "3. Backward Pass ‚Üí Compute Gradients  \n",
    "4. Optimizer ‚Üí Update Weights  \n",
    "5. Repeat for multiple epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9427b3e8",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>üîü Practical Tips for Stable Training</h3>\n",
    "\n",
    "‚úÖ Normalize or standardize input data.  \n",
    "‚úÖ Start with **learning rate = 0.001** for Adam.  \n",
    "‚úÖ Monitor training vs validation loss (watch for overfitting).  \n",
    "‚úÖ Use **early stopping** if loss stops improving.  \n",
    "‚úÖ Always experiment ‚Äî no single optimizer fits all problems.\n",
    "\n",
    "> Training stability depends equally on good data preprocessing, proper activation choice, and optimizer tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e60301",
   "metadata": {},
   "source": [
    "### <h3 style='text-align:center;'>‚úÖ Summary & Next Steps</h3>\n",
    "\n",
    "- **Loss functions** measure how wrong predictions are.  \n",
    "- **Optimizers** adjust weights to reduce loss efficiently.  \n",
    "- Common losses: MSE, MAE, BCE, CCE.  \n",
    "- Common optimizers: Adam, RMSProp, SGD.  \n",
    "- Adam = default choice for most deep learning tasks.\n",
    "\n",
    "**Next:** Proceed to `06_Vanishing_Gradient_&_Regularization/` to understand training stability issues and solutions (dropout, batch norm, etc.).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
