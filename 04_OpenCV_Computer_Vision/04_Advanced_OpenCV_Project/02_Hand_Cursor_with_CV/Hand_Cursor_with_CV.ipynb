{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c5886e",
   "metadata": {},
   "source": [
    "<h2 style='text-align:center;'>‚úã Hand Cursor & Face Drawing ‚Äî MediaPipe + OpenCV</h2>\n",
    "\n",
    "This notebook demonstrates two interactive applications: (1) a wrist-driven air-draw cursor and (2) face-aware index-finger drawing using Haar cascade face detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84fbce",
   "metadata": {},
   "source": [
    "<h2 style='text-align:center;'>üß† Theory</h2>\n",
    "\n",
    "We use MediaPipe Hands to extract hand landmarks. Wrist (landmark 0) or index fingertip (landmark 8) coordinates are converted to pixel space and used as a virtual cursor for drawing operations. Face detection is used to constrain drawing to the face ROI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89765341",
   "metadata": {},
   "source": [
    "<h2 style='text-align:center;'>‚öôÔ∏è Setup & Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, mediapipe as mp, time\n",
    "print('Run locally (VSCode) for webcam + GUI support.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc0fc68",
   "metadata": {},
   "source": [
    "<h2 style='text-align:center;'>üíª Run Applications</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e1d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hand_cursor_basic import run_hand_cursor\n",
    "# run_hand_cursor(hud=True)\n",
    "\n",
    "# from hand_cursor_face_draw import run_face_draw\n",
    "# run_face_draw(hud=True)\n",
    "\n",
    "print('Uncomment above lines to run apps locally.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae05ab",
   "metadata": {},
   "source": [
    "<h2 style='text-align:center;'>üìú Raw Scripts (Sir's originals)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb96da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pygame\n",
    "\n",
    "# Initialize pygame\n",
    "pygame.init()\n",
    "\n",
    "# Define constants\n",
    "WIDTH, HEIGHT = 640, 480\n",
    "FPS = 60\n",
    "BRUSH_SIZE = 10\n",
    "\n",
    "# Set up game window\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"Draw with Your Hand!\")\n",
    "\n",
    "# Colors\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "BRUSH_COLOR = (0, 255, 0)\n",
    "\n",
    "# Hand Tracking Setup\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to detect hand gestures and draw\n",
    "def detect_hand_gesture(frame):\n",
    "    # Convert the frame to RGB for hand tracking\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    hand_landmarks = None\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand in results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand, mp_hands.HAND_CONNECTIONS)\n",
    "            hand_landmarks = hand\n",
    "\n",
    "    return hand_landmarks\n",
    "\n",
    "# Function to convert hand coordinates to screen coordinates\n",
    "def hand_to_screen_coordinates(hand_landmarks, frame_width, frame_height):\n",
    "    wrist_x = int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * frame_width)\n",
    "    wrist_y = int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * frame_height)\n",
    "    return wrist_x, wrist_y\n",
    "\n",
    "# Main loop\n",
    "def main():\n",
    "    screen.fill(WHITE)  # Fill the screen with white background\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # Initialize webcam\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    last_position = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Flip the frame horizontally (mirror effect)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Detect hand landmarks\n",
    "        hand_landmarks = detect_hand_gesture(frame)\n",
    "        \n",
    "        # If hand is detected, draw on the screen\n",
    "        if hand_landmarks:\n",
    "            wrist_x, wrist_y = hand_to_screen_coordinates(hand_landmarks, WIDTH, HEIGHT)\n",
    "\n",
    "            # Draw a circle or brush where the hand's wrist is located\n",
    "            if last_position:\n",
    "                pygame.draw.line(screen, BRUSH_COLOR, last_position, (wrist_x, wrist_y), BRUSH_SIZE)\n",
    "            \n",
    "            last_position = (wrist_x, wrist_y)\n",
    "\n",
    "        # Show the webcam feed (for user to see hand movement)\n",
    "        cv2.imshow(\"Hand Tracking Feed\", frame)\n",
    "\n",
    "        # Draw the pygame surface\n",
    "        pygame.display.update()\n",
    "\n",
    "        # Handle pygame events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                cap.release()\n",
    "                pygame.quit()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "            elif event.type == pygame.KEYDOWN and event.key == pygame.K_ESCAPE:\n",
    "                cap.release()\n",
    "                pygame.quit()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "\n",
    "        clock.tick(FPS)  # Control the frame rate\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94502b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pygame\n",
    "import numpy as np\n",
    "\n",
    "# Initialize pygame\n",
    "pygame.init()\n",
    "\n",
    "# Define constants\n",
    "WIDTH, HEIGHT = 640, 480\n",
    "FPS = 60\n",
    "BRUSH_SIZE = 10\n",
    "\n",
    "# Set up the game window for drawing on top of the camera feed\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"Draw with Your Hand!\")\n",
    "\n",
    "# Colors\n",
    "WHITE = (255, 255, 255)\n",
    "BRUSH_COLOR = (0, 255, 0)\n",
    "\n",
    "# Hand Tracking Setup\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to detect hand gestures and draw\n",
    "def detect_hand_gesture(frame):\n",
    "    # Convert the frame to RGB for hand tracking\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    hand_landmarks = None\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand in results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand, mp_hands.HAND_CONNECTIONS)\n",
    "            hand_landmarks = hand\n",
    "\n",
    "    return hand_landmarks\n",
    "\n",
    "# Function to convert hand coordinates to screen coordinates\n",
    "def hand_to_screen_coordinates(hand_landmarks, frame_width, frame_height):\n",
    "    wrist_x = int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * frame_width)\n",
    "    wrist_y = int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * frame_height)\n",
    "    return wrist_x, wrist_y\n",
    "\n",
    "# Main loop\n",
    "def main():\n",
    "    # Set up the webcam capture\n",
    "    cap = cv2.VideoCapture(0)  # Initialize webcam\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    # Initialize previous position for drawing\n",
    "    last_position = None\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Flip the frame horizontally (mirror effect)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Detect hand landmarks\n",
    "        hand_landmarks = detect_hand_gesture(frame)\n",
    "        \n",
    "        # Draw on the screen if hand is detected\n",
    "        if hand_landmarks:\n",
    "            wrist_x, wrist_y = hand_to_screen_coordinates(hand_landmarks, WIDTH, HEIGHT)\n",
    "\n",
    "            # Draw a line from the last position to the new wrist position\n",
    "            if last_position:\n",
    "                pygame.draw.line(screen, BRUSH_COLOR, last_position, (wrist_x, wrist_y), BRUSH_SIZE)\n",
    "            \n",
    "            last_position = (wrist_x, wrist_y)\n",
    "\n",
    "        # Convert the OpenCV frame to a format suitable for pygame (Surface)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_surface = pygame.surfarray.make_surface(frame_rgb)\n",
    "\n",
    "        # Display the webcam feed as the background\n",
    "        screen.blit(frame_surface, (0, 0))\n",
    "\n",
    "        # Update the screen with the drawing on top of the camera feed\n",
    "        pygame.display.update()\n",
    "\n",
    "        # Handle pygame events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                cap.release()\n",
    "                pygame.quit()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "            elif event.type == pygame.KEYDOWN and event.key == pygame.K_ESCAPE:\n",
    "                cap.release()\n",
    "                pygame.quit()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "\n",
    "        # Frame rate\n",
    "        clock.tick(FPS)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cd1134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pygame\n",
    "import numpy as np\n",
    "\n",
    "# Initialize pygame\n",
    "pygame.init()\n",
    "\n",
    "# Define constants\n",
    "WIDTH, HEIGHT = 640, 480\n",
    "FPS = 60\n",
    "BRUSH_SIZE = 10\n",
    "MASK_COLOR = (0, 0, 0)  # Color for the mask (black)\n",
    "\n",
    "# Set up the game window\n",
    "screen = pygame.display.set_mode((WIDTH, HEIGHT))\n",
    "pygame.display.set_caption(\"Draw on Face with Finger!\")\n",
    "\n",
    "# Colors\n",
    "WHITE = (255, 255, 255)\n",
    "BRUSH_COLOR = (0, 255, 0)\n",
    "\n",
    "# Hand Tracking Setup\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, min_tracking_confidence=0.5)\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Face Detection Setup (Using Haar Cascade)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Function to detect hand gestures and draw\n",
    "def detect_hand_gesture(frame):\n",
    "    # Convert the frame to RGB for hand tracking\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    hand_landmarks = None\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand in results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand, mp_hands.HAND_CONNECTIONS)\n",
    "            hand_landmarks = hand\n",
    "\n",
    "    return hand_landmarks\n",
    "\n",
    "# Function to convert hand coordinates to screen coordinates\n",
    "def hand_to_screen_coordinates(hand_landmarks, frame_width, frame_height):\n",
    "    index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "    x = int(index_finger_tip.x * frame_width)\n",
    "    y = int(index_finger_tip.y * frame_height)\n",
    "    return x, y\n",
    "\n",
    "# Function to detect faces and return the face region\n",
    "def detect_face(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)  # Detect faces\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = frame[y:y+h, x:x+w]  # Region of interest for the face\n",
    "        return (x, y, w, h), face_roi\n",
    "    return None, None\n",
    "\n",
    "# Main loop\n",
    "def main():\n",
    "    # Set up the webcam capture\n",
    "    cap = cv2.VideoCapture(0)  # Initialize webcam\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    # Initialize previous position for drawing\n",
    "    last_position = None\n",
    "    mask_image = None  # Store the mask image\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Flip the frame horizontally (mirror effect)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        # Detect face and apply a mask to the face region\n",
    "        face_coords, face_roi = detect_face(frame)\n",
    "        if face_coords:\n",
    "            x, y, w, h = face_coords\n",
    "            # Create a blank mask over the face region\n",
    "            if mask_image is None:\n",
    "                mask_image = np.zeros_like(frame)\n",
    "            mask_image[y:y+h, x:x+w] = (0, 0, 0)  # Black mask on face\n",
    "\n",
    "        # Detect hand landmarks\n",
    "        hand_landmarks = detect_hand_gesture(frame)\n",
    "        \n",
    "        # Draw on the screen if hand is detected\n",
    "        if hand_landmarks:\n",
    "            x, y = hand_to_screen_coordinates(hand_landmarks, WIDTH, HEIGHT)\n",
    "\n",
    "            # Draw a circle at the finger tip position (for drawing)\n",
    "            if last_position:\n",
    "                # Draw line from last finger position to current position\n",
    "                pygame.draw.line(screen, BRUSH_COLOR, last_position, (x, y), BRUSH_SIZE)\n",
    "            \n",
    "            # Update last position\n",
    "            last_position = (x, y)\n",
    "\n",
    "        # If there's a mask (from finger drawing), apply it over the face region\n",
    "        if mask_image is not None:\n",
    "            frame = cv2.addWeighted(frame, 1, mask_image, 0.5, 0)  # Merge mask with webcam frame\n",
    "\n",
    "        # Convert the OpenCV frame to a format suitable for pygame (Surface)\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame_surface = pygame.surfarray.make_surface(frame_rgb)\n",
    "\n",
    "        # Display the webcam feed as the background\n",
    "        screen.blit(frame_surface, (0, 0))\n",
    "\n",
    "        # Update the screen with the drawing on top of the camera feed\n",
    "        pygame.display.update()\n",
    "\n",
    "        # Handle pygame events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                cap.release()\n",
    "                pygame.quit()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "            elif event.type == pygame.KEYDOWN and event.key == pygame.K_ESCAPE:\n",
    "                cap.release()\n",
    "                pygame.quit()\n",
    "                cv2.destroyAllWindows()\n",
    "                return\n",
    "\n",
    "        # Frame rate\n",
    "        clock.tick(FPS)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a74fe7",
   "metadata": {},
   "source": [
    "<h2 style='text-align:center;'>‚úÖ Summary & Next Steps</h2>\n",
    "\n",
    "We created two production-ready scripts: `hand_cursor_basic.py` and `hand_cursor_face_draw.py`. Next: integrate color/brush controls or export strokes as SVG paths."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
