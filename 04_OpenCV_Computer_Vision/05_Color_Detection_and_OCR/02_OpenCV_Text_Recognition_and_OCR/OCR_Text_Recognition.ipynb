{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a0e959a",
   "metadata": {},
   "source": [
    "# <h2 style='text-align:center;'>OCR ‚Äî OpenCV Text Recognition</h2>\n",
    "\n",
    "This notebook demonstrates a robust OCR pipeline using **OpenCV** for preprocessing and **Tesseract OCR** (via `pytesseract`) for text extraction. The companion script `ocr_text_detection.py` (VSCode-friendly) performs the actual extraction; use this notebook to explore preprocessing steps and visualize intermediate results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f08d9b",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Setup\n",
    "\n",
    "Install Python packages (run in your environment):\n",
    "\n",
    "```bash\n",
    "pip install opencv-python numpy pytesseract pillow matplotlib\n",
    "```\n",
    "\n",
    "**Important:** Tesseract OCR is a system program and must be installed separately (not via pip). Instructions below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd28424",
   "metadata": {},
   "source": [
    "### üîß Install Tesseract (quick guide)\n",
    "\n",
    "- **Windows (recommended):** Download installer from UB-Mannheim builds: https://github.com/UB-Mannheim/tesseract/wiki and run the `.exe`. During install, check **Add to PATH**. Typical path: `C:\\Program Files\\Tesseract-OCR\\tesseract.exe`.\n",
    "- **macOS:** `brew install tesseract`\n",
    "- **Ubuntu/Debian:** `sudo apt update && sudo apt install tesseract-ocr`\n",
    "\n",
    "After installing, verify in terminal:\n",
    "```\n",
    "tesseract --version\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76726ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "print('tesseract on PATH ->', bool(shutil.which('tesseract')))\n",
    "# If False, set pytesseract.pytesseract.tesseract_cmd to the full path to your tesseract executable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0a3509",
   "metadata": {},
   "source": [
    "## üì∑ Load sample image\n",
    "\n",
    "We use the sample images in `sample_images/`. If you don't have images, add them to that folder or change the `img_path` to your image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "sample = Path('sample_images')\n",
    "imgs = list(sample.glob('*'))\n",
    "if not imgs:\n",
    "    print('No sample images found in sample_images/. Please add images (e.g. images.jpg) and re-run.')\n",
    "else:\n",
    "    img_path = imgs[0]\n",
    "    print('Using:', img_path)\n",
    "    img = cv2.imread(str(img_path))\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(10,6)); plt.imshow(img_rgb); plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c1ef80",
   "metadata": {},
   "source": [
    "## üîç Preprocessing recipes\n",
    "\n",
    "We will demonstrate three common preprocessing approaches before passing images to Tesseract:\n",
    "\n",
    "- **Otsu thresholding** (`thresh`) ‚Äî good for high-contrast text\n",
    "- **Adaptive thresholding** (`adaptive`) ‚Äî robust to varying illumination\n",
    "- **Bilateral smoothing** (`smooth`) ‚Äî denoising while preserving edges\n",
    "\n",
    "Use whichever works best for your image; try all three if unsure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714eee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_show(path, mode='thresh'):\n",
    "    import cv2\n",
    "    from matplotlib import pyplot as plt\n",
    "    img = cv2.imread(str(path))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    if mode == 'thresh':\n",
    "        _, proc = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    elif mode == 'adaptive':\n",
    "        proc = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY,11,2)\n",
    "    else:\n",
    "        proc = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "    plt.figure(figsize=(10,6)); plt.imshow(proc, cmap='gray'); plt.title(mode); plt.axis('off')\n",
    "\n",
    "# show all three for the first sample image if present\n",
    "from pathlib import Path\n",
    "s = Path('sample_images')\n",
    "imgs = list(s.glob('*'))\n",
    "if imgs:\n",
    "    for m in ['thresh','adaptive','smooth']:\n",
    "        preprocess_and_show(imgs[0], m)\n",
    "else:\n",
    "    print('Add sample images to sample_images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeaa71f",
   "metadata": {},
   "source": [
    "## ‚úçÔ∏è Extract text using pytesseract (example)\n",
    "Below we call pytesseract on the preprocessed image. If `tesseract` is not installed or not on PATH, this will raise an error ‚Äî refer to the installation steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787cded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "s = Path('sample_images')\n",
    "imgs = list(s.glob('*'))\n",
    "if imgs:\n",
    "    img_path = imgs[0]\n",
    "    img = cv2.imread(str(img_path))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, proc = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    try:\n",
    "        text = pytesseract.image_to_string(proc, config='--psm 6')\n",
    "        print('----- Recognized Text -----')\n",
    "        print(text)\n",
    "    except Exception as e:\n",
    "        print('pytesseract error:', e)\n",
    "else:\n",
    "    print('No sample image available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c8ea6e",
   "metadata": {},
   "source": [
    "## üß∞ Use the backend script\n",
    "We created a companion script `ocr_text_detection.py` that you can run from the command line. Example:\n",
    "\n",
    "```bash\n",
    "python ocr_text_detection.py --image sample_images/images.jpg --mode thresh --save\n",
    "```\n",
    "\n",
    "This script automatically detects Tesseract (if on PATH) and shows the processed image, printing extracted text to console and (optionally) saving it as `.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546ed142",
   "metadata": {},
   "source": [
    "## üì¶ Next steps & enhancements\n",
    "- Use `pytesseract.image_to_data()` to get bounding boxes and confidence scores.\n",
    "- Add morphological operations (dilate/erode) for noisy documents.\n",
    "- Extend to multi-page PDF OCR using `pdf2image`.\n",
    "- Integrate with Streamlit front-end for easy uploads and downloads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc34328",
   "metadata": {},
   "source": [
    "## ‚úÖ Troubleshooting\n",
    "- If you see `pytesseract` errors: ensure **Tesseract OCR** is installed and on PATH.\n",
    "- If recognized text is poor: try different preprocessing modes, resize the image, or restrict the character whitelist via tesseract config."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
